{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zr695/IMLO-OpenAssessment/blob/main/IMLO_OpenAssessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaWvitsVZAdE",
        "outputId": "ffe97e29-7b59-4003-89bb-eb69cffc13ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [01:42<00:00, 3380961.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 568450.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 20143679.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "# %pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from torch.autograd import Variable\n",
        "from google.colab import runtime\n",
        "# from torchviz import make_dot\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((500, 500)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "training_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split='train',\n",
        "    download=True,\n",
        "    transform=data_transform\n",
        ")\n",
        "validation_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split='val',\n",
        "    download=True,\n",
        "    transform=transforms.Compose([transforms.Resize((500, 500)), transforms.ToTensor()])\n",
        ")\n",
        "test_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split='test',\n",
        "    download=True,\n",
        "    transform=transforms.Compose([transforms.Resize((500, 500)), transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=128)\n",
        "validate_dataloader = DataLoader(validation_data, batch_size=128)\n",
        "test_dataloader = DataLoader(test_data, batch_size=128)\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            # nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 125 * 125, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 102)\n",
        "\n",
        "        )\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()\n",
        "dev = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Using device:{dev}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy_input = torch.randn(128, 3, 500, 500)\n",
        "# make_dot(\n",
        "#     model(dummy_input),\n",
        "#     params=dict(model.named_parameters())).render(\"nnSVG\", format=\"pdf\"\n",
        "#     )"
      ],
      "metadata": {
        "id": "81iKmu0hGe-c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ujENhhLZAX9Y"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0007\n",
        "batch_size = 128\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rZ140M4kAhHW"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2spKuqZMAlOD"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 2 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X, y in dataloader:\n",
        "          pred = model(X)\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ3v_XZ0QKSa",
        "outputId": "8876baca-4be9-4d09-b7ac-f0914b06a29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.631837  [  128/ 1020]\n",
            "loss: 4.752569  [  384/ 1020]\n",
            "loss: 4.897707  [  640/ 1020]\n",
            "loss: 4.755946  [  896/ 1020]\n",
            "Accuracy: 1.4%, Avg loss: 4.624297 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 4.622291  [  128/ 1020]\n",
            "loss: 4.678061  [  384/ 1020]\n",
            "loss: 4.630188  [  640/ 1020]\n",
            "loss: 4.661627  [  896/ 1020]\n",
            "Accuracy: 1.3%, Avg loss: 4.623082 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 4.621310  [  128/ 1020]\n",
            "loss: 4.654305  [  384/ 1020]\n",
            "loss: 4.599571  [  640/ 1020]\n",
            "loss: 4.657775  [  896/ 1020]\n",
            "Accuracy: 1.2%, Avg loss: 4.620535 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 4.602549  [  128/ 1020]\n",
            "loss: 4.669586  [  384/ 1020]\n",
            "loss: 4.589456  [  640/ 1020]\n",
            "loss: 4.648163  [  896/ 1020]\n",
            "Accuracy: 2.5%, Avg loss: 4.615544 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 4.594187  [  128/ 1020]\n",
            "loss: 4.684540  [  384/ 1020]\n",
            "loss: 4.585526  [  640/ 1020]\n",
            "loss: 4.638796  [  896/ 1020]\n",
            "Accuracy: 3.0%, Avg loss: 4.608410 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 4.595572  [  128/ 1020]\n",
            "loss: 4.655686  [  384/ 1020]\n",
            "loss: 4.567979  [  640/ 1020]\n",
            "loss: 4.660911  [  896/ 1020]\n",
            "Accuracy: 3.2%, Avg loss: 4.599562 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 4.562610  [  128/ 1020]\n",
            "loss: 4.681714  [  384/ 1020]\n",
            "loss: 4.561643  [  640/ 1020]\n",
            "loss: 4.634282  [  896/ 1020]\n",
            "Accuracy: 4.0%, Avg loss: 4.589371 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 4.536813  [  128/ 1020]\n",
            "loss: 4.661120  [  384/ 1020]\n",
            "loss: 4.547513  [  640/ 1020]\n",
            "loss: 4.645217  [  896/ 1020]\n",
            "Accuracy: 3.1%, Avg loss: 4.577665 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 4.521462  [  128/ 1020]\n",
            "loss: 4.666598  [  384/ 1020]\n",
            "loss: 4.542371  [  640/ 1020]\n",
            "loss: 4.632998  [  896/ 1020]\n",
            "Accuracy: 3.0%, Avg loss: 4.566822 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 4.494680  [  128/ 1020]\n",
            "loss: 4.653847  [  384/ 1020]\n",
            "loss: 4.538765  [  640/ 1020]\n",
            "loss: 4.634445  [  896/ 1020]\n",
            "Accuracy: 3.4%, Avg loss: 4.553859 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 4.481498  [  128/ 1020]\n",
            "loss: 4.645429  [  384/ 1020]\n",
            "loss: 4.532946  [  640/ 1020]\n",
            "loss: 4.612614  [  896/ 1020]\n",
            "Accuracy: 3.4%, Avg loss: 4.543629 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 4.445417  [  128/ 1020]\n",
            "loss: 4.658979  [  384/ 1020]\n",
            "loss: 4.529006  [  640/ 1020]\n",
            "loss: 4.620338  [  896/ 1020]\n",
            "Accuracy: 3.6%, Avg loss: 4.531980 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 4.449029  [  128/ 1020]\n",
            "loss: 4.648045  [  384/ 1020]\n",
            "loss: 4.509461  [  640/ 1020]\n",
            "loss: 4.597335  [  896/ 1020]\n",
            "Accuracy: 3.5%, Avg loss: 4.522085 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 4.433407  [  128/ 1020]\n",
            "loss: 4.654181  [  384/ 1020]\n",
            "loss: 4.509303  [  640/ 1020]\n",
            "loss: 4.568918  [  896/ 1020]\n",
            "Accuracy: 3.6%, Avg loss: 4.509675 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 4.395739  [  128/ 1020]\n",
            "loss: 4.631423  [  384/ 1020]\n",
            "loss: 4.476454  [  640/ 1020]\n",
            "loss: 4.589646  [  896/ 1020]\n",
            "Accuracy: 3.7%, Avg loss: 4.498074 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 4.365605  [  128/ 1020]\n",
            "loss: 4.621584  [  384/ 1020]\n",
            "loss: 4.462747  [  640/ 1020]\n",
            "loss: 4.580525  [  896/ 1020]\n",
            "Accuracy: 4.0%, Avg loss: 4.486173 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 4.362689  [  128/ 1020]\n",
            "loss: 4.586507  [  384/ 1020]\n",
            "loss: 4.440722  [  640/ 1020]\n",
            "loss: 4.549252  [  896/ 1020]\n",
            "Accuracy: 3.7%, Avg loss: 4.474818 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 4.329072  [  128/ 1020]\n",
            "loss: 4.579956  [  384/ 1020]\n",
            "loss: 4.430517  [  640/ 1020]\n",
            "loss: 4.558835  [  896/ 1020]\n",
            "Accuracy: 4.1%, Avg loss: 4.462482 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 4.302205  [  128/ 1020]\n",
            "loss: 4.553294  [  384/ 1020]\n",
            "loss: 4.405918  [  640/ 1020]\n",
            "loss: 4.522214  [  896/ 1020]\n",
            "Accuracy: 4.6%, Avg loss: 4.451014 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 4.312136  [  128/ 1020]\n",
            "loss: 4.555795  [  384/ 1020]\n",
            "loss: 4.403930  [  640/ 1020]\n",
            "loss: 4.514023  [  896/ 1020]\n",
            "Accuracy: 3.9%, Avg loss: 4.436681 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 4.267879  [  128/ 1020]\n",
            "loss: 4.543221  [  384/ 1020]\n",
            "loss: 4.371093  [  640/ 1020]\n",
            "loss: 4.496864  [  896/ 1020]\n",
            "Accuracy: 4.0%, Avg loss: 4.425997 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 4.243361  [  128/ 1020]\n",
            "loss: 4.510478  [  384/ 1020]\n",
            "loss: 4.335948  [  640/ 1020]\n",
            "loss: 4.473224  [  896/ 1020]\n",
            "Accuracy: 3.5%, Avg loss: 4.415135 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 4.249188  [  128/ 1020]\n",
            "loss: 4.487515  [  384/ 1020]\n",
            "loss: 4.338410  [  640/ 1020]\n",
            "loss: 4.473058  [  896/ 1020]\n",
            "Accuracy: 4.2%, Avg loss: 4.404546 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 4.199978  [  128/ 1020]\n",
            "loss: 4.482520  [  384/ 1020]\n",
            "loss: 4.328914  [  640/ 1020]\n",
            "loss: 4.478384  [  896/ 1020]\n",
            "Accuracy: 4.0%, Avg loss: 4.390047 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 4.197851  [  128/ 1020]\n",
            "loss: 4.470821  [  384/ 1020]\n",
            "loss: 4.280695  [  640/ 1020]\n",
            "loss: 4.469546  [  896/ 1020]\n",
            "Accuracy: 4.1%, Avg loss: 4.378385 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 4.191674  [  128/ 1020]\n",
            "loss: 4.432670  [  384/ 1020]\n",
            "loss: 4.246606  [  640/ 1020]\n",
            "loss: 4.435349  [  896/ 1020]\n",
            "Accuracy: 5.0%, Avg loss: 4.365839 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 4.180561  [  128/ 1020]\n",
            "loss: 4.438354  [  384/ 1020]\n",
            "loss: 4.231541  [  640/ 1020]\n",
            "loss: 4.465337  [  896/ 1020]\n",
            "Accuracy: 5.6%, Avg loss: 4.350684 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 4.160448  [  128/ 1020]\n",
            "loss: 4.432247  [  384/ 1020]\n",
            "loss: 4.237600  [  640/ 1020]\n",
            "loss: 4.425442  [  896/ 1020]\n",
            "Accuracy: 5.6%, Avg loss: 4.337689 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 4.155665  [  128/ 1020]\n",
            "loss: 4.418447  [  384/ 1020]\n",
            "loss: 4.232607  [  640/ 1020]\n",
            "loss: 4.441520  [  896/ 1020]\n",
            "Accuracy: 5.9%, Avg loss: 4.326281 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 4.123824  [  128/ 1020]\n",
            "loss: 4.378971  [  384/ 1020]\n",
            "loss: 4.147628  [  640/ 1020]\n",
            "loss: 4.399420  [  896/ 1020]\n",
            "Accuracy: 5.3%, Avg loss: 4.316614 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 4.122425  [  128/ 1020]\n",
            "loss: 4.343041  [  384/ 1020]\n",
            "loss: 4.151857  [  640/ 1020]\n",
            "loss: 4.388381  [  896/ 1020]\n",
            "Accuracy: 5.7%, Avg loss: 4.304661 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 4.082562  [  128/ 1020]\n",
            "loss: 4.344005  [  384/ 1020]\n",
            "loss: 4.147536  [  640/ 1020]\n",
            "loss: 4.364254  [  896/ 1020]\n",
            "Accuracy: 6.2%, Avg loss: 4.293455 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 4.067077  [  128/ 1020]\n",
            "loss: 4.338698  [  384/ 1020]\n",
            "loss: 4.151934  [  640/ 1020]\n",
            "loss: 4.384463  [  896/ 1020]\n",
            "Accuracy: 5.9%, Avg loss: 4.281127 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 4.045762  [  128/ 1020]\n",
            "loss: 4.306274  [  384/ 1020]\n",
            "loss: 4.056022  [  640/ 1020]\n",
            "loss: 4.343821  [  896/ 1020]\n",
            "Accuracy: 7.0%, Avg loss: 4.269384 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 4.056891  [  128/ 1020]\n",
            "loss: 4.296366  [  384/ 1020]\n",
            "loss: 4.005092  [  640/ 1020]\n",
            "loss: 4.312338  [  896/ 1020]\n",
            "Accuracy: 6.3%, Avg loss: 4.257058 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 4.017278  [  128/ 1020]\n",
            "loss: 4.264080  [  384/ 1020]\n",
            "loss: 3.997472  [  640/ 1020]\n",
            "loss: 4.284415  [  896/ 1020]\n",
            "Accuracy: 6.7%, Avg loss: 4.240757 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 3.972450  [  128/ 1020]\n",
            "loss: 4.277778  [  384/ 1020]\n",
            "loss: 4.015311  [  640/ 1020]\n",
            "loss: 4.303469  [  896/ 1020]\n",
            "Accuracy: 6.9%, Avg loss: 4.227009 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 3.977565  [  128/ 1020]\n",
            "loss: 4.227903  [  384/ 1020]\n",
            "loss: 3.967133  [  640/ 1020]\n",
            "loss: 4.286821  [  896/ 1020]\n",
            "Accuracy: 6.4%, Avg loss: 4.212043 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 3.939392  [  128/ 1020]\n",
            "loss: 4.163802  [  384/ 1020]\n",
            "loss: 3.919216  [  640/ 1020]\n",
            "loss: 4.268753  [  896/ 1020]\n",
            "Accuracy: 7.0%, Avg loss: 4.197234 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 3.929297  [  128/ 1020]\n",
            "loss: 4.200410  [  384/ 1020]\n",
            "loss: 3.929983  [  640/ 1020]\n",
            "loss: 4.262337  [  896/ 1020]\n",
            "Accuracy: 7.3%, Avg loss: 4.182457 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 3.903849  [  128/ 1020]\n",
            "loss: 4.139325  [  384/ 1020]\n",
            "loss: 3.916216  [  640/ 1020]\n",
            "loss: 4.279905  [  896/ 1020]\n",
            "Accuracy: 8.2%, Avg loss: 4.168428 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 3.904148  [  128/ 1020]\n",
            "loss: 4.133014  [  384/ 1020]\n",
            "loss: 3.878466  [  640/ 1020]\n",
            "loss: 4.231266  [  896/ 1020]\n",
            "Accuracy: 8.8%, Avg loss: 4.157173 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 3.853403  [  128/ 1020]\n",
            "loss: 4.132923  [  384/ 1020]\n",
            "loss: 3.806625  [  640/ 1020]\n",
            "loss: 4.236083  [  896/ 1020]\n",
            "Accuracy: 9.0%, Avg loss: 4.141690 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 3.804644  [  128/ 1020]\n",
            "loss: 4.128240  [  384/ 1020]\n",
            "loss: 3.841303  [  640/ 1020]\n",
            "loss: 4.182450  [  896/ 1020]\n",
            "Accuracy: 8.7%, Avg loss: 4.128558 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 3.809741  [  128/ 1020]\n",
            "loss: 4.079104  [  384/ 1020]\n",
            "loss: 3.785526  [  640/ 1020]\n",
            "loss: 4.209848  [  896/ 1020]\n",
            "Accuracy: 9.4%, Avg loss: 4.106864 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 3.768327  [  128/ 1020]\n",
            "loss: 4.061087  [  384/ 1020]\n",
            "loss: 3.704029  [  640/ 1020]\n",
            "loss: 4.174699  [  896/ 1020]\n",
            "Accuracy: 9.5%, Avg loss: 4.092434 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 3.752716  [  128/ 1020]\n",
            "loss: 3.993098  [  384/ 1020]\n",
            "loss: 3.708695  [  640/ 1020]\n",
            "loss: 4.146779  [  896/ 1020]\n",
            "Accuracy: 10.6%, Avg loss: 4.074877 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 3.708262  [  128/ 1020]\n",
            "loss: 4.019233  [  384/ 1020]\n",
            "loss: 3.618855  [  640/ 1020]\n",
            "loss: 4.105647  [  896/ 1020]\n",
            "Accuracy: 10.4%, Avg loss: 4.061707 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 3.703631  [  128/ 1020]\n",
            "loss: 3.946352  [  384/ 1020]\n",
            "loss: 3.613573  [  640/ 1020]\n",
            "loss: 4.096783  [  896/ 1020]\n",
            "Accuracy: 10.1%, Avg loss: 4.045475 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 3.676160  [  128/ 1020]\n",
            "loss: 3.987917  [  384/ 1020]\n",
            "loss: 3.543079  [  640/ 1020]\n",
            "loss: 4.085663  [  896/ 1020]\n",
            "Accuracy: 10.1%, Avg loss: 4.032184 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 3.627350  [  128/ 1020]\n",
            "loss: 3.948710  [  384/ 1020]\n",
            "loss: 3.537855  [  640/ 1020]\n",
            "loss: 4.027021  [  896/ 1020]\n",
            "Accuracy: 10.4%, Avg loss: 4.016184 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 3.574730  [  128/ 1020]\n",
            "loss: 3.911552  [  384/ 1020]\n",
            "loss: 3.462121  [  640/ 1020]\n",
            "loss: 4.059171  [  896/ 1020]\n",
            "Accuracy: 11.3%, Avg loss: 3.998301 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 3.578995  [  128/ 1020]\n",
            "loss: 3.852942  [  384/ 1020]\n",
            "loss: 3.465995  [  640/ 1020]\n",
            "loss: 4.062725  [  896/ 1020]\n",
            "Accuracy: 10.8%, Avg loss: 3.978919 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 3.565142  [  128/ 1020]\n",
            "loss: 3.856181  [  384/ 1020]\n",
            "loss: 3.384501  [  640/ 1020]\n",
            "loss: 4.033041  [  896/ 1020]\n",
            "Accuracy: 11.0%, Avg loss: 3.962233 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 3.548569  [  128/ 1020]\n",
            "loss: 3.839119  [  384/ 1020]\n",
            "loss: 3.395429  [  640/ 1020]\n",
            "loss: 4.002326  [  896/ 1020]\n",
            "Accuracy: 12.2%, Avg loss: 3.939260 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 3.500448  [  128/ 1020]\n",
            "loss: 3.847572  [  384/ 1020]\n",
            "loss: 3.391215  [  640/ 1020]\n",
            "loss: 3.965608  [  896/ 1020]\n",
            "Accuracy: 12.5%, Avg loss: 3.927630 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 3.502033  [  128/ 1020]\n",
            "loss: 3.787046  [  384/ 1020]\n",
            "loss: 3.289822  [  640/ 1020]\n",
            "loss: 4.000597  [  896/ 1020]\n",
            "Accuracy: 12.4%, Avg loss: 3.909826 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 3.463314  [  128/ 1020]\n",
            "loss: 3.723659  [  384/ 1020]\n",
            "loss: 3.302655  [  640/ 1020]\n",
            "loss: 3.953544  [  896/ 1020]\n",
            "Accuracy: 12.9%, Avg loss: 3.901049 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 3.414663  [  128/ 1020]\n",
            "loss: 3.706167  [  384/ 1020]\n",
            "loss: 3.243109  [  640/ 1020]\n",
            "loss: 3.912618  [  896/ 1020]\n",
            "Accuracy: 13.6%, Avg loss: 3.878127 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 3.416950  [  128/ 1020]\n",
            "loss: 3.682352  [  384/ 1020]\n",
            "loss: 3.230361  [  640/ 1020]\n",
            "loss: 3.846483  [  896/ 1020]\n",
            "Accuracy: 13.0%, Avg loss: 3.862584 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 3.428068  [  128/ 1020]\n",
            "loss: 3.699071  [  384/ 1020]\n",
            "loss: 3.232607  [  640/ 1020]\n",
            "loss: 3.845269  [  896/ 1020]\n",
            "Accuracy: 13.0%, Avg loss: 3.847098 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 3.364036  [  128/ 1020]\n",
            "loss: 3.681981  [  384/ 1020]\n",
            "loss: 3.243238  [  640/ 1020]\n",
            "loss: 3.875597  [  896/ 1020]\n",
            "Accuracy: 13.8%, Avg loss: 3.827425 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 3.397379  [  128/ 1020]\n",
            "loss: 3.623849  [  384/ 1020]\n",
            "loss: 3.122526  [  640/ 1020]\n",
            "loss: 3.829566  [  896/ 1020]\n",
            "Accuracy: 13.5%, Avg loss: 3.811955 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 3.278860  [  128/ 1020]\n",
            "loss: 3.612508  [  384/ 1020]\n",
            "loss: 3.052332  [  640/ 1020]\n",
            "loss: 3.796535  [  896/ 1020]\n",
            "Accuracy: 15.0%, Avg loss: 3.798553 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 3.246080  [  128/ 1020]\n",
            "loss: 3.638293  [  384/ 1020]\n",
            "loss: 3.137968  [  640/ 1020]\n",
            "loss: 3.687324  [  896/ 1020]\n",
            "Accuracy: 14.8%, Avg loss: 3.785628 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 3.239681  [  128/ 1020]\n",
            "loss: 3.521660  [  384/ 1020]\n",
            "loss: 3.029400  [  640/ 1020]\n",
            "loss: 3.742294  [  896/ 1020]\n",
            "Accuracy: 15.3%, Avg loss: 3.766278 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 3.229744  [  128/ 1020]\n",
            "loss: 3.504721  [  384/ 1020]\n",
            "loss: 2.990349  [  640/ 1020]\n",
            "loss: 3.701434  [  896/ 1020]\n",
            "Accuracy: 14.4%, Avg loss: 3.759347 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 3.154869  [  128/ 1020]\n",
            "loss: 3.564129  [  384/ 1020]\n",
            "loss: 2.935124  [  640/ 1020]\n",
            "loss: 3.708531  [  896/ 1020]\n",
            "Accuracy: 14.9%, Avg loss: 3.738704 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 3.178087  [  128/ 1020]\n",
            "loss: 3.600340  [  384/ 1020]\n",
            "loss: 2.959082  [  640/ 1020]\n",
            "loss: 3.647083  [  896/ 1020]\n",
            "Accuracy: 15.4%, Avg loss: 3.727343 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 3.113764  [  128/ 1020]\n",
            "loss: 3.507837  [  384/ 1020]\n",
            "loss: 2.935263  [  640/ 1020]\n",
            "loss: 3.633349  [  896/ 1020]\n",
            "Accuracy: 15.1%, Avg loss: 3.712146 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 3.137872  [  128/ 1020]\n",
            "loss: 3.457299  [  384/ 1020]\n",
            "loss: 2.870731  [  640/ 1020]\n",
            "loss: 3.605204  [  896/ 1020]\n",
            "Accuracy: 15.0%, Avg loss: 3.700915 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 3.138595  [  128/ 1020]\n",
            "loss: 3.413339  [  384/ 1020]\n",
            "loss: 2.831646  [  640/ 1020]\n",
            "loss: 3.648737  [  896/ 1020]\n",
            "Accuracy: 15.5%, Avg loss: 3.686616 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 3.156178  [  128/ 1020]\n",
            "loss: 3.312713  [  384/ 1020]\n",
            "loss: 2.947587  [  640/ 1020]\n",
            "loss: 3.625034  [  896/ 1020]\n",
            "Accuracy: 15.9%, Avg loss: 3.672475 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 3.069012  [  128/ 1020]\n",
            "loss: 3.322970  [  384/ 1020]\n",
            "loss: 2.851171  [  640/ 1020]\n",
            "loss: 3.515750  [  896/ 1020]\n",
            "Accuracy: 15.0%, Avg loss: 3.665960 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 3.032814  [  128/ 1020]\n",
            "loss: 3.319334  [  384/ 1020]\n",
            "loss: 2.724569  [  640/ 1020]\n",
            "loss: 3.550518  [  896/ 1020]\n",
            "Accuracy: 15.5%, Avg loss: 3.654526 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 2.987397  [  128/ 1020]\n",
            "loss: 3.382020  [  384/ 1020]\n",
            "loss: 2.834300  [  640/ 1020]\n",
            "loss: 3.464801  [  896/ 1020]\n",
            "Accuracy: 16.0%, Avg loss: 3.637830 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 3.004934  [  128/ 1020]\n",
            "loss: 3.381977  [  384/ 1020]\n",
            "loss: 2.722895  [  640/ 1020]\n",
            "loss: 3.502389  [  896/ 1020]\n",
            "Accuracy: 15.7%, Avg loss: 3.629649 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 2.926467  [  128/ 1020]\n",
            "loss: 3.240633  [  384/ 1020]\n",
            "loss: 2.697273  [  640/ 1020]\n",
            "loss: 3.551974  [  896/ 1020]\n",
            "Accuracy: 16.2%, Avg loss: 3.619438 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 2.984945  [  128/ 1020]\n",
            "loss: 3.260346  [  384/ 1020]\n",
            "loss: 2.766522  [  640/ 1020]\n",
            "loss: 3.369572  [  896/ 1020]\n",
            "Accuracy: 16.0%, Avg loss: 3.607512 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 2.899720  [  128/ 1020]\n",
            "loss: 3.215886  [  384/ 1020]\n",
            "loss: 2.668059  [  640/ 1020]\n",
            "loss: 3.430309  [  896/ 1020]\n",
            "Accuracy: 16.3%, Avg loss: 3.598864 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 2.892140  [  128/ 1020]\n",
            "loss: 3.180054  [  384/ 1020]\n",
            "loss: 2.633688  [  640/ 1020]\n",
            "loss: 3.430004  [  896/ 1020]\n",
            "Accuracy: 16.5%, Avg loss: 3.585560 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 2.932209  [  128/ 1020]\n",
            "loss: 3.215747  [  384/ 1020]\n",
            "loss: 2.593474  [  640/ 1020]\n",
            "loss: 3.426133  [  896/ 1020]\n",
            "Accuracy: 16.8%, Avg loss: 3.566794 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 2.796758  [  128/ 1020]\n",
            "loss: 3.136061  [  384/ 1020]\n",
            "loss: 2.605872  [  640/ 1020]\n",
            "loss: 3.299129  [  896/ 1020]\n",
            "Accuracy: 16.7%, Avg loss: 3.569397 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 2.898355  [  128/ 1020]\n",
            "loss: 3.106912  [  384/ 1020]\n",
            "loss: 2.604421  [  640/ 1020]\n",
            "loss: 3.325086  [  896/ 1020]\n",
            "Accuracy: 17.2%, Avg loss: 3.561636 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 2.807462  [  128/ 1020]\n",
            "loss: 3.146656  [  384/ 1020]\n",
            "loss: 2.618379  [  640/ 1020]\n",
            "loss: 3.324501  [  896/ 1020]\n",
            "Accuracy: 17.5%, Avg loss: 3.543271 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 2.745042  [  128/ 1020]\n",
            "loss: 3.144610  [  384/ 1020]\n",
            "loss: 2.532299  [  640/ 1020]\n",
            "loss: 3.230919  [  896/ 1020]\n",
            "Accuracy: 17.5%, Avg loss: 3.540947 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 2.806052  [  128/ 1020]\n",
            "loss: 3.135790  [  384/ 1020]\n",
            "loss: 2.512890  [  640/ 1020]\n",
            "loss: 3.243508  [  896/ 1020]\n",
            "Accuracy: 18.1%, Avg loss: 3.520241 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 2.693556  [  128/ 1020]\n",
            "loss: 2.999872  [  384/ 1020]\n",
            "loss: 2.510786  [  640/ 1020]\n",
            "loss: 3.234488  [  896/ 1020]\n",
            "Accuracy: 17.7%, Avg loss: 3.512702 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 2.680951  [  128/ 1020]\n",
            "loss: 3.046651  [  384/ 1020]\n",
            "loss: 2.524839  [  640/ 1020]\n",
            "loss: 3.207896  [  896/ 1020]\n",
            "Accuracy: 18.2%, Avg loss: 3.507681 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 2.636693  [  128/ 1020]\n",
            "loss: 3.004750  [  384/ 1020]\n",
            "loss: 2.517285  [  640/ 1020]\n",
            "loss: 3.226761  [  896/ 1020]\n",
            "Accuracy: 18.2%, Avg loss: 3.500336 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 2.656866  [  128/ 1020]\n",
            "loss: 3.021689  [  384/ 1020]\n",
            "loss: 2.388321  [  640/ 1020]\n",
            "loss: 3.102074  [  896/ 1020]\n",
            "Accuracy: 18.2%, Avg loss: 3.492232 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 2.591185  [  128/ 1020]\n",
            "loss: 2.952686  [  384/ 1020]\n",
            "loss: 2.289684  [  640/ 1020]\n",
            "loss: 3.103727  [  896/ 1020]\n",
            "Accuracy: 18.6%, Avg loss: 3.481940 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 2.547029  [  128/ 1020]\n",
            "loss: 2.946378  [  384/ 1020]\n",
            "loss: 2.380713  [  640/ 1020]\n",
            "loss: 3.141070  [  896/ 1020]\n",
            "Accuracy: 18.6%, Avg loss: 3.478131 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 2.607040  [  128/ 1020]\n",
            "loss: 2.932440  [  384/ 1020]\n",
            "loss: 2.420905  [  640/ 1020]\n",
            "loss: 3.145741  [  896/ 1020]\n",
            "Accuracy: 19.1%, Avg loss: 3.474048 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 2.578247  [  128/ 1020]\n",
            "loss: 2.884816  [  384/ 1020]\n",
            "loss: 2.363817  [  640/ 1020]\n",
            "loss: 3.143632  [  896/ 1020]\n",
            "Accuracy: 18.7%, Avg loss: 3.466107 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 2.549329  [  128/ 1020]\n",
            "loss: 2.766037  [  384/ 1020]\n",
            "loss: 2.333827  [  640/ 1020]\n",
            "loss: 3.030720  [  896/ 1020]\n",
            "Accuracy: 19.6%, Avg loss: 3.458192 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 2.507294  [  128/ 1020]\n",
            "loss: 2.764383  [  384/ 1020]\n",
            "loss: 2.333615  [  640/ 1020]\n",
            "loss: 2.987071  [  896/ 1020]\n",
            "Accuracy: 19.3%, Avg loss: 3.465280 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 2.496419  [  128/ 1020]\n",
            "loss: 2.835785  [  384/ 1020]\n",
            "loss: 2.188976  [  640/ 1020]\n",
            "loss: 3.031814  [  896/ 1020]\n",
            "Accuracy: 20.3%, Avg loss: 3.440605 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 2.536673  [  128/ 1020]\n",
            "loss: 2.819081  [  384/ 1020]\n",
            "loss: 2.225685  [  640/ 1020]\n",
            "loss: 3.010236  [  896/ 1020]\n",
            "Accuracy: 19.6%, Avg loss: 3.440535 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 2.524190  [  128/ 1020]\n",
            "loss: 2.785297  [  384/ 1020]\n",
            "loss: 2.311637  [  640/ 1020]\n",
            "loss: 2.896176  [  896/ 1020]\n",
            "Accuracy: 19.6%, Avg loss: 3.434194 \n",
            "\n",
            "Final Test Accuracy:\n"
          ]
        }
      ],
      "source": [
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(validate_dataloader, model, loss_fn)\n",
        "print(f\"Final Test Accuracy:\")\n",
        "test_accuracy = test_loop(test_dataloader, model, loss_fn)\n",
        "torch.save(model.state_dict(),'flowers-102.pth')\n",
        "runtime.unassign()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}